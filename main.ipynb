{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Fresh_Gills -> 613 files\n",
      "Training/Nonfresh_Eyes -> 1028 files\n",
      "Training/Fresh_Eyes -> 233 files\n",
      "Training/Nonfresh_Gills -> 1265 files\n",
      "Testing/Fresh_Gills -> 80 files\n",
      "Testing/Nonfresh_Eyes -> 257 files\n",
      "Testing/Fresh_Eyes -> 134 files\n",
      "Testing/Nonfresh_Gills -> 316 files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "root_path = \"dataset\"\n",
    "\n",
    "def count_files(path):\n",
    "    return len([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]) if os.path.exists(path) else 0\n",
    "\n",
    "summary = []\n",
    "\n",
    "# Loop kategori di dalam Training dan Testing\n",
    "for mode in [\"Training\", \"Testing\"]:\n",
    "    mode_path = os.path.join(root_path, mode)\n",
    "    if os.path.isdir(mode_path):\n",
    "        for category in os.listdir(mode_path):\n",
    "            category_path = os.path.join(mode_path, category)\n",
    "            if os.path.isdir(category_path):\n",
    "                file_count = count_files(category_path)\n",
    "                summary.append(f\"{mode}/{category} -> {file_count} files\")\n",
    "\n",
    "# Cetak hasil\n",
    "for line in summary:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Dataset path (ubah sesuai kebutuhan Anda)\n",
    "sdir = '/kaggle/input/fish-classification-dataset/'\n",
    "\n",
    "# Bangun DataFrame\n",
    "filepaths = []\n",
    "labels = []\n",
    "\n",
    "for data_type in ['Training', 'Testing']:\n",
    "    data_path = os.path.join(sdir, data_type)\n",
    "    for klass in os.listdir(data_path):\n",
    "        class_path = os.path.join(data_path, klass)\n",
    "        if os.path.isdir(class_path):\n",
    "            for file in os.listdir(class_path):\n",
    "                filepaths.append(os.path.join(class_path, file))\n",
    "                labels.append(klass)\n",
    "\n",
    "df = pd.DataFrame({'filepaths': filepaths, 'labels': labels})\n",
    "training_df = df[df['filepaths'].str.contains('/Training/')].copy()\n",
    "testing_df = df[df['filepaths'].str.contains('/Testing/')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Split training menjadi training dan validation\n",
    "train_df, valid_df = train_test_split(training_df, test_size=0.15, stratify=training_df['labels'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# 2. DATA GENERATOR\n",
    "# ================================================\n",
    "height, width, channels = 224, 224, 3\n",
    "img_size = (height, width)\n",
    "batch_size = 64\n",
    "class_mode = 'categorical'\n",
    "\n",
    "# Augmentasi data latih\n",
    "train_aug = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Augmentasi untuk validasi dan testing\n",
    "val_test_aug = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Generator\n",
    "train_gen = train_aug.flow_from_dataframe(train_df, x_col='filepaths', y_col='labels',\n",
    "                                          target_size=img_size, class_mode=class_mode,\n",
    "                                          batch_size=batch_size, shuffle=True)\n",
    "\n",
    "valid_gen = val_test_aug.flow_from_dataframe(valid_df, x_col='filepaths', y_col='labels',\n",
    "                                             target_size=img_size, class_mode=class_mode,\n",
    "                                             batch_size=batch_size, shuffle=True)\n",
    "\n",
    "testing_gen = val_test_aug.flow_from_dataframe(testing_df, x_col='filepaths', y_col='labels',\n",
    "                                               target_size=img_size, class_mode=class_mode,\n",
    "                                               batch_size=batch_size, shuffle=False)\n",
    "\n",
    "classes = list(train_gen.class_indices.keys())\n",
    "class_count = len(classes)\n",
    "labels = train_gen.classes\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
    "class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# 3. MODEL: EfficientNetV2 + Fine-Tuning\n",
    "# ================================================\n",
    "base_model = tf.keras.models.load_model('/kaggle/input/efficientnetv2/keras/efficientnetv2_s_imagenet_classifier/2')\n",
    "base_model = tf.keras.Model(inputs=base_model.input, outputs=base_model.layers[-4].output)\n",
    "\n",
    "# Fine-tuning beberapa layer terakhir\n",
    "for layer in base_model.layers[:-20]:\n",
    "    layer.trainable = False\n",
    "for layer in base_model.layers[-20:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "inputs = layers.Input(shape=(height, width, channels))\n",
    "x = base_model(inputs, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(class_count, activation='softmax')(x)\n",
    "\n",
    "model = models.Model(inputs, outputs)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Jumlah data latih:\", train_gen.samples)\n",
    "print(\"Jumlah data validasi:\", valid_gen.samples)\n",
    "print(\"Jumlah data testing:\", testing_gen.samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# 4. TRAINING MODEL DENGAN CLASS WEIGHT\n",
    "# ================================================\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=5, restore_best_weights=True, monitor='val_loss'),\n",
    "    ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_accuracy')\n",
    "]\n",
    "\n",
    "steps_per_epoch = train_gen.n // train_gen.batch_size\n",
    "validation_steps = valid_gen.n // valid_gen.batch_size\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=valid_gen,\n",
    "    epochs=30,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weights\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# 5. EVALUASI MODEL\n",
    "# ================================================\n",
    "test_loss, test_acc = model.evaluate(testing_gen)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "y_pred = model.predict(testing_gen)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = testing_gen.classes\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=classes, yticklabels=classes)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report:\\n\", classification_report(y_true, y_pred_classes, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# 6. VISUALISASI HISTORY\n",
    "# ================================================\n",
    "def plot_history(history):\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    # Accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Accuracy')\n",
    "\n",
    "    # Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Loss')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4610057,
     "sourceId": 7859190,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 2797,
     "modelInstanceId": 4608,
     "sourceId": 6158,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
